{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLTHNDBaPFOKum+lJuG2ZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngchanseo/Hon.Gong.Machine-SNU/blob/main/(04_2_1)_SGD_CLASSIFIER_p200.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#확률적 경사 하강법\n",
        " Stochastic Gradient Dscent 확률적 경사 하강법\n",
        "- 대표적인 점진적 학습\n",
        "- 훈련세트에서 랜덤하게 하나의 샘플을 선택하여 가파른 경사를 조금 내려간다. 그 다음 훈련세트에서  선택하여 경사를 조금 내려간다. 이런식으로 전체 샘플을 모두 사용할때까지 계속\n",
        "\n",
        "Minibatch Gradient descent 미니 배치 경사 하강법\n",
        "- 1개씩 말고, 무작위로 여러개의 샘플을 선택해서 경사 하강법을 수행\n",
        "\n",
        "batch gradient descent 배치 경사 하강법\n",
        "- 극단적으로 한번 경사로를 따라 이동하기 위해전체 샘플을 사용함\n",
        "\n",
        "# 손실 함수\n",
        "\n",
        "손실함수loss function\n",
        "- 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지 츠겆ㅇ하는 기준\n",
        "\n",
        "#로지스틱 손실 함수 Logistic loss function (Binary cross-entropy loss function)\n",
        "- 양성 클래스 (Target =1)일때, 손실은 -log(예측확률): 확률이 1에서 멀어질 수록 손실은 아주 큰 양수가 됨\n",
        "- 음성 클래스 (Target = 0)일 때 손실은 -log(1-예측확률): 예측 확률이 9에서 멀어질 수록 손실은 아주 큰 양수가 됨"
      ],
      "metadata": {
        "id": "uR-50vmwnI3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SGD Classifier"
      ],
      "metadata": {
        "id": "jpmLqLqmstqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "fish = pd.read_csv('https://raw.githubusercontent.com/youngchanseo/Hon.Gong.Machine-SNU/main/(04_2_0)%20Raw%20Data.csv')\n",
        "#fish = pd.read_csv('https://bit.ly/fish_csv_data')\n",
        " # 그 다음 Specieis 열(Target data)을 제외한 5개는 입력 데이터로 사용함\n",
        "#import numpy as np\n",
        "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
        "fish_target = fish['Species'].to_numpy()"
      ],
      "metadata": {
        "id": "HmCNzuZspUn-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#사이킷런의 train_test_split() 함수를 사용해 이 데이터를 훈련세트와 테스트 세트로 나눔\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state = 42)"
      ],
      "metadata": {
        "id": "pF-SNNC4xT2b"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 세트와 테스트 세트의 특성을 표준화 전처리함\n",
        "# 꼭 훈련세트에서 학습한 통계값으로 테스트 세트로 변환해야함\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "ss.fit(train_input)\n",
        "train_scaled = ss.transform(train_input)\n",
        "test_scaled = ss.transform(test_input)"
      ],
      "metadata": {
        "id": "0HtQbw8cwrxg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGDClassifie의 객체를 만들때 2개의 매개변수를 지정함.\n",
        "#loss 는 손실함수의 종류를 지정함. 여기에서는 loss = 'log'로 지정하여, 로지스틱 손실함수를 지정\n",
        "sc = SGDClassifier(loss='log', max_iter=10, random_state =42) #max_iter: 수행할 에포크 횟수를 지정 (여기에서는 10회로 지정)\n",
        "sc.fit(train_scaled, train_target)\n",
        "#훈련세트와 테스트 세트에서 정확도 점수 출력\n",
        "print(\"scaled train score: \", sc.score(from sklearn.preprocessing import StandardScaler))\n",
        "print(\"scaled test score: \", sc.score(from sklearn.preprocessing import StandardScaler))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndXGkw6Zws7O",
        "outputId": "269c3665-58f5-432f-98d2-3b093a6e8c46"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scaled train score:  0.773109243697479\n",
            "scaled test score:  0.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Convergence Warning  경고: 모델이 충분하게 수렴하지 않았다는 경고임\n",
        "\n",
        "max_iter매개변수 값을 늘려주는 것이 좋다\n",
        "\n",
        "오류가 아닌 경고"
      ],
      "metadata": {
        "id": "b9g2qh4fs-vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#g\\ SGDClassifier객체를 다시 만들지 않고 훈련한 모델 sc를 추가로 더 훈련해보자\n",
        "#모델을 이어서 훈련할때는 partial_fit() method를 이용함. 이 method는 fit()method 와 사용법이 같지만, 호출할 때 마다 1 에포크씩 이어서 후녈ㄴ가능\n",
        "sc.partial_fit(train_scaled, train_target)\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsHpl7y11LpG",
        "outputId": "200c8f36-23ee-449f-81ce-64b31c1baef7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8151260504201681\n",
            "0.85\n"
          ]
        }
      ]
    }
  ]
}